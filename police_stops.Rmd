---
title: "Exploring 2016 San Diego Police Stop Data"
output:
  html_document: default
  html_notebook: default
---

```{r load packages}
library(tidyverse, verbose = T)
library(knitr, verbose = T)
library(stringr, verbose = T)
```

```{r read race table}
race <- read_csv("p_stop_data/vehicle_stops_race_codes.csv")
```

```{r read dictionary}
dict <- read_csv("p_stop_data/vehicle_stops_dictionary.csv")
```

```{r read stops}
stops <- read_csv("p_stop_data/vehicle_stops_2016_datasd.csv", 
                  col_types = cols(stop_id = col_character()), 
                  na = "NA")
```

Let's clean up the some of the string values: 

```{r}
stops$searched <- str_replace_all(stops$searched, c("n" = "N", "\\\\" = "NA"))
stops$arrested <- str_replace_all(stops$arrested, c("n" = "N", "\\\\" = "NA"))
```

```{r}
str(stops)
```

```{r read details}
details <- read_csv("p_stop_data/vehicle_stops_search_details_2016_datasd.csv", 
                    col_types = cols(stop_id = col_character()))
```

```{r}
str(details)
```

```{r merge}
comb <- left_join(stops, details, by = "stop_id")
```

How many times are `stop_id` values duplicated in the `comb` dataframe? 

```{r}
comb_ids <- comb %>% 
  count(stop_id) %>% 
  arrange(desc(n))
```

How many times are `stop_id` values duplicated in the `stops` dataframe? 

```{r}
stops_ids <- stops %>% 
  count(stop_id) %>% 
  arrange(desc(n))
```

It appears that doing the `left_join` with `stops` and `details` results in more duplicates of `stop_ids`, probably because there are multiple observations in `details` for each of the `stop_ids`. The result is that new rows are created in the resulting `comb` dataset.

Let's focus first on analyzing the `stops` dataset without joining to the `details` dataset so that we don't misrepresent the number of observations originally collected in the `stops` dataset. 

## Data Quality: NAs

The research paper notes that in 201  4 there were 144164 traffic stops and in 2015 there were 115405 traffic stops. In 2016 there were `r nrow(stops)` stops. Here are the percentage of each variable that were NA: 

```{r}
missing <- tibble(
  stop_description = c(
    "driver_race", 
    "driver_age", 
    "driver_gender", 
    "residency_status", 
    "service_area", 
    "stop_cause", 
    "stop_time", 
    "stop_date", 
    "arrested", 
    "searched", 
    "obtained_consent", 
    "contraband_found", 
    "property_seized"
  ), 
  perc_missing = c(
    mean(is.na(stops$subject_race)), 
    mean(is.na(stops$subject_age)), 
    mean(is.na(stops$subject_sex)), 
    mean(is.na(stops$sd_resident)), 
    mean(is.na(stops$service_area)), 
    mean(is.na(stops$stop_cause)), 
    mean(is.na(stops$stop_time)), 
    mean(is.na(stops$stop_date)), 
    mean(is.na(stops$arrested)), 
    mean(is.na(stops$searched)), 
    mean(is.na(stops$obtained_consent)), 
    mean(is.na(stops$contraband_found)), 
    mean(is.na(stops$property_seized))
  )
) 

missing <- missing %>% 
  mutate(perc_missing = round(perc_missing * 100, 2)) %>% 
  arrange(desc(perc_missing))

kable(missing)
```

```{r}
qplot(data = stops, subject_age, subject_sex, size = 3, alpha = .5)
```

```{r}
qplot(data = stops, searched)
```

```{r}
qplot(data = stops, stop_cause) + 
  coord_flip()
```

```{r}
qplot(data = stops, service_area)
```